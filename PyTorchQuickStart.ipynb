{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To better understand how PyTorch works, I requested ChatGPT to generate a quickstart guide. I then followed this guide while also referring to the official PyTorch documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by importing PyTorch and any other necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can create tensors (PyTorch’s fundamental data structure) in several ways. Here are some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor of zeros:\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "Tensor of ones:\n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "Tensor from list:\n",
      " tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "Random tensor:\n",
      " tensor([[0.2553, 0.3853, 0.1101],\n",
      "        [0.5632, 0.9935, 0.0277],\n",
      "        [0.8100, 0.8897, 0.2769]])\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor of zeros\n",
    "x = torch.zeros(3, 3)\n",
    "print(\"Tensor of zeros:\\n\", x)\n",
    "\n",
    "# Create a tensor of ones\n",
    "y = torch.ones(3, 3)\n",
    "print(\"Tensor of ones:\\n\", y)\n",
    "\n",
    "# Create a tensor from a Python list\n",
    "z = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
    "print(\"Tensor from list:\\n\", z)\n",
    "\n",
    "# Create a random tensor\n",
    "random_tensor = torch.rand(3, 3)\n",
    "print(\"Random tensor:\\n\", random_tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can perform a variety of operations on tensors. Here are some examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element-wise sum:\n",
      " tensor([5., 7., 9.])\n",
      "Dot product:\n",
      " tensor(32.)\n",
      "Matrix multiplication:\n",
      " tensor([[19, 22],\n",
      "        [43, 50]])\n",
      "Reshaped tensor:\n",
      " tensor([[1.],\n",
      "        [2.],\n",
      "        [3.]])\n"
     ]
    }
   ],
   "source": [
    "# Element-wise addition\n",
    "a = torch.tensor([1.0, 2.0, 3.0])\n",
    "b = torch.tensor([4.0, 5.0, 6.0])\n",
    "sum_tensor = a + b\n",
    "print(\"Element-wise sum:\\n\", sum_tensor)\n",
    "\n",
    "# Matrix multiplication (dot product)\n",
    "dot_product = torch.dot(a, b)\n",
    "print(\"Dot product:\\n\", dot_product)\n",
    "\n",
    "# Matrix multiplication (for 2D tensors)\n",
    "matrix1 = torch.tensor([[1, 2], [3, 4]])\n",
    "matrix2 = torch.tensor([[5, 6], [7, 8]])\n",
    "matrix_multiplication = torch.matmul(matrix1, matrix2)\n",
    "print(\"Matrix multiplication:\\n\", matrix_multiplication)\n",
    "\n",
    "# Reshaping a tensor\n",
    "reshaped_tensor = a.view(3, 1)\n",
    "print(\"Reshaped tensor:\\n\", reshaped_tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s see how PyTorch handles automatic differentiation (Autograd):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient of x:\n",
      " tensor([6.])\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor and enable gradient tracking\n",
    "x = torch.tensor([3.0], requires_grad=True)\n",
    "\n",
    "# Perform an operation\n",
    "y = x ** 2\n",
    "\n",
    "# Compute gradients\n",
    "y.backward()\n",
    "\n",
    "# Print the gradient (dy/dx)\n",
    "print(\"Gradient of x:\\n\", x.grad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s define a simple neural network. Here, we’ll create a feedforward network with one hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleNet(\n",
      "  (fc1): Linear(in_features=2, out_features=4, bias=True)\n",
      "  (fc2): Linear(in_features=4, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define a simple neural network\n",
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 4)  # Fully connected layer (2 input features, 4 neurons)\n",
    "        self.fc2 = nn.Linear(4, 1)  # Output layer (4 neurons, 1 output)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))  # Apply ReLU activation function\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model = SimpleNet()\n",
    "\n",
    "# Print the model architecture\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training, you need a loss function and an optimizer. Here's how you can define them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a loss function (Mean Squared Error)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Define an optimizer (Stochastic Gradient Descent)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's simulate training the network on some random data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.07616738975048065\n",
      "Epoch 10, Loss: 0.07422588765621185\n",
      "Epoch 20, Loss: 0.07329786568880081\n",
      "Epoch 30, Loss: 0.07276806980371475\n",
      "Epoch 40, Loss: 0.07240810990333557\n",
      "Epoch 50, Loss: 0.07213012129068375\n",
      "Epoch 60, Loss: 0.07189889252185822\n",
      "Epoch 70, Loss: 0.07169922441244125\n",
      "Epoch 80, Loss: 0.07152363657951355\n",
      "Epoch 90, Loss: 0.07136775553226471\n"
     ]
    }
   ],
   "source": [
    "# Simulate some input data (batch_size=5, 2 features)\n",
    "inputs = torch.randn(5, 2)\n",
    "\n",
    "# Simulate the corresponding target data\n",
    "targets = torch.randn(5, 1)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(100):\n",
    "    # Zero the gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Forward pass: compute predicted outputs by passing inputs to the model\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    # Compute the loss\n",
    "    loss = criterion(outputs, targets)\n",
    "\n",
    "    # Backward pass: compute gradients\n",
    "    loss.backward()\n",
    "\n",
    "    # Update model parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print the loss every 10 epochs\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have a GPU available, you can move your model and tensors to the GPU for faster computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.07122863084077835\n",
      "Epoch 10, Loss: 0.07110394537448883\n",
      "Epoch 20, Loss: 0.07099183648824692\n",
      "Epoch 30, Loss: 0.07089066505432129\n",
      "Epoch 40, Loss: 0.07079906761646271\n",
      "Epoch 50, Loss: 0.07071582227945328\n",
      "Epoch 60, Loss: 0.07063988596200943\n",
      "Epoch 70, Loss: 0.07057031244039536\n",
      "Epoch 80, Loss: 0.07050631940364838\n",
      "Epoch 90, Loss: 0.07044719159603119\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA (GPU) is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Move model to GPU\n",
    "model = model.to(device)\n",
    "\n",
    "# Move inputs and targets to GPU\n",
    "inputs = inputs.to(device)\n",
    "targets = targets.to(device)\n",
    "\n",
    "# Training loop with GPU\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training your model, you can save it and later reload it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleNet(\n",
       "  (fc1): Linear(in_features=2, out_features=4, bias=True)\n",
       "  (fc2): Linear(in_features=4, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model's state_dict\n",
    "torch.save(model.state_dict(), 'simple_net.pth')\n",
    "\n",
    "# Create a new instance of the model\n",
    "model_new = SimpleNet()\n",
    "\n",
    "# Load the saved state_dict into the new model\n",
    "model_new.load_state_dict(torch.load('simple_net.pth'))\n",
    "\n",
    "# Set the model to evaluation mode (if needed)\n",
    "model_new.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch provides tools to load and iterate over data efficiently using the DataLoader class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1:\n",
      "Input batch:\n",
      " tensor([[-0.0492, -0.2575],\n",
      "        [ 0.3752,  2.4848],\n",
      "        [-0.6219, -0.0186],\n",
      "        [-0.2602, -1.5549],\n",
      "        [ 0.1875,  0.3585],\n",
      "        [ 0.4695, -0.1040],\n",
      "        [ 0.1428, -0.8554],\n",
      "        [ 0.4228,  0.4990],\n",
      "        [ 0.2511,  0.0760],\n",
      "        [ 2.9968, -0.6627]])\n",
      "Target batch:\n",
      " tensor([[ 1.4559],\n",
      "        [-2.6418],\n",
      "        [ 0.5649],\n",
      "        [ 0.4986],\n",
      "        [ 1.4350],\n",
      "        [ 0.5621],\n",
      "        [ 1.4103],\n",
      "        [-0.6509],\n",
      "        [-0.6911],\n",
      "        [ 0.8793]])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Create some dummy data (inputs and targets)\n",
    "inputs = torch.randn(100, 2)  # 100 samples, 2 features\n",
    "targets = torch.randn(100, 1)  # 100 targets\n",
    "\n",
    "# Create a dataset\n",
    "dataset = TensorDataset(inputs, targets)\n",
    "\n",
    "# Create a DataLoader to load the data in batches\n",
    "dataloader = DataLoader(dataset, batch_size=10, shuffle=True)\n",
    "\n",
    "# Iterate over batches\n",
    "for batch_idx, (input_batch, target_batch) in enumerate(dataloader):\n",
    "    print(f\"Batch {batch_idx + 1}:\")\n",
    "    print(\"Input batch:\\n\", input_batch)\n",
    "    print(\"Target batch:\\n\", target_batch)\n",
    "    break  # Only show the first batch for simplicity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using the model for inference (testing), you should set it to evaluation mode using .eval() to ensure that layers like dropout or batch normalization behave correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test outputs:\n",
      " tensor([[-0.3710],\n",
      "        [-0.1559],\n",
      "        [-0.3670],\n",
      "        [-0.1599],\n",
      "        [-0.4335]])\n"
     ]
    }
   ],
   "source": [
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Perform inference (without gradients)\n",
    "with torch.no_grad():\n",
    "    # Simulate new input data\n",
    "    test_inputs = torch.randn(5, 2)\n",
    "    test_outputs = model(test_inputs)\n",
    "\n",
    "print(\"Test outputs:\\n\", test_outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here’s a simple pipeline that combines creating the model, training it, and evaluating it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 1.074761986732483\n",
      "Epoch 10, Loss: 1.0521851778030396\n",
      "Epoch 20, Loss: 1.0380479097366333\n",
      "Epoch 30, Loss: 1.029058814048767\n",
      "Epoch 40, Loss: 1.0232292413711548\n",
      "Epoch 50, Loss: 1.0193463563919067\n",
      "Epoch 60, Loss: 1.0166529417037964\n",
      "Epoch 70, Loss: 1.0147151947021484\n",
      "Epoch 80, Loss: 1.0132513046264648\n",
      "Epoch 90, Loss: 1.0121207237243652\n",
      "Test outputs:\n",
      " tensor([[-0.0002],\n",
      "        [ 0.0490],\n",
      "        [-0.0002],\n",
      "        [ 0.0416],\n",
      "        [ 0.0566]])\n"
     ]
    }
   ],
   "source": [
    "# Create the model, loss function, and optimizer\n",
    "model = SimpleNet()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Simulate training and testing data\n",
    "inputs = torch.randn(100, 2)\n",
    "targets = torch.randn(100, 1)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_inputs = torch.randn(5, 2)\n",
    "    test_outputs = model(test_inputs)\n",
    "    print(\"Test outputs:\\n\", test_outputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These code snippets should give you a good foundation to start using PyTorch. You can experiment with creating models, training them, using GPUs, and managing data with DataLoader. Feel free to modify the code and add your own layers, loss functions, and data pipelines!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
